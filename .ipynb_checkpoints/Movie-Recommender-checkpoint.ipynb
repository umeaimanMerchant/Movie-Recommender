{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img align=\"left\" src=\"./images/movie_camera.png\"     style=\" width:40px;  \" > Movie Recommender Systems\n",
    "\n",
    "\n",
    "In this exercise, you will implement content-based filtering using a neural network to build a recommender system for movies. \n",
    "\n",
    "# Outline <img align=\"left\" src=\"./images/film_reel.png\"     style=\" width:40px;  \" >\n",
    "- [ 1 - Packages](#1)\n",
    "- [ 2 - Movie ratings dataset](#2)\n",
    "- [ 3 - Intro: Content-based filtering with a neural network](#3)\n",
    "- [ 4 - Preparing the training data](#4)\n",
    "- [ 5 - Modelling Neural Network for content-based filtering](#5)\n",
    "- [ 6 - Model Evaluation](#6)\n",
    "    - [ 6.1 Prediction for New User](#6.1)\n",
    "    - [ 6.2 Finding Similar Items](#6.2)\n",
    "- [ 7 - Model Evaluation](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from numpy import genfromtxt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tabulate\n",
    "from recsysNN_utils import *\n",
    "pd.set_option(\"display.precision\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Movie ratings dataset \n",
    "The data set is derived from the [MovieLens ml-latest-small](https://grouplens.org/datasets/movielens/latest/) dataset. \n",
    "\n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. <https://doi.org/10.1145/2827872>]\n",
    "\n",
    "The original dataset has 9000 movies rated by 600 users with ratings on a scale of 0.5 to 5 in 0.5 step increments. The dataset has been reduced in size to focus on movies from the years since 2000 and popular genres. The reduced dataset has $n_u = 395$ users and $n_m= 694$ movies. For each movie, the dataset provides a movie title, release date, and one or more genres. For example \"Toy Story 3\" was released in 2010 and has several genres: \"Adventure|Animation|Children|Comedy|Fantasy|IMAX\".  This dataset contains little information about users other than their ratings. This dataset is used to create training vectors for the neural networks described below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Content-based filtering with a neural network\n",
    "\n",
    "There are two types of `Recommendation system`\n",
    "1. Collaborative filtering\n",
    "2. Content-based filtering\n",
    "\n",
    "The goal of a *Collaborative filtering* recommender system is to generate two vectors: For each user, a 'parameter vector' that embodies the movie tastes of a user. For each movie, a feature vector of the same size which embodies some description of the movie. The dot product of the two vectors plus the bias term should produce an estimate of the rating the user might give to that movie.\n",
    "\n",
    "*Content-based filtering* generates a user and movie feature vector and recognizes there may be other information available about the user and/or movie that may improve the prediction. The additional information is provided to a neural network which then generates the user and movie vector as shown below.\n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"./images/RecSysNN.png\"   style=\"width:500px;height:280px;\" ></center>\n",
    "</figure>\n",
    "\n",
    "The movie content provided to the network is a combination of the original data and some 'engineered features'. The original features are the year the movie was released and the movie's genre presented as a one-hot vector. There are 14 genres. The engineered feature is an average rating derived from the user ratings. Movies with multiple genre have a training vector per genre. \n",
    "\n",
    "The user content is composed of only engineered features. A per genre average rating is computed per user. Additionally, a user id, rating count and rating average are available, but are not included in the training or prediction content. They are useful in interpreting data.\n",
    "\n",
    "The training set consists of all the ratings made by the users in the data set. The user and movie/item vectors are presented to the above network together as a training set. The user vector is the same for all the movies rated by the user. \n",
    "\n",
    "Below, let's load and display some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training vectors: 58187\n"
     ]
    }
   ],
   "source": [
    "# Load Data, set configuration variables\n",
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data()\n",
    "\n",
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "scaledata = True  # applies the standard scalar to data if true\n",
    "print(f\"Number of training vectors: {len(item_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie features: ['movie id', 'year', 'ave rating', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Horror', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller']\n"
     ]
    }
   ],
   "source": [
    "# columns header for movies\n",
    "print(f\"Movie features: {item_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features: ['user id', 'rating count', 'rating ave', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Horror', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller']\n"
     ]
    }
   ],
   "source": [
    "# columns header for users\n",
    "print(f\"User features: {user_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 records in user data\n",
    "pprint_train(user_train, user_features, uvs,  u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\\n<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 records in movie data\n",
    "pprint_train(item_train, item_features, ivs, i_s, maxcount=5, user=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[:5]: [4.  4.  4.  3.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "# first 5 records in label\n",
    "print(f\"y_train[:5]: {y_train[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A training example consists of a row from both tables and a rating from y_train.\n",
    " \n",
    "Some of the user and item/movie features are not used in training. Above, the features in brackets \"[]\" such as the \"user id\", \"rating count\" and \"rating ave\" are not included when the model is trained and used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 Preparing the training data\n",
    "We'll scale the input features using the [scikit learn StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale training data\n",
    "if scaledata:\n",
    "    item_train_save = item_train\n",
    "    user_train_save = user_train\n",
    "\n",
    "    scalerItem = StandardScaler()\n",
    "    scalerItem.fit(item_train)\n",
    "    item_train = scalerItem.transform(item_train)\n",
    "\n",
    "    scalerUser = StandardScaler()\n",
    "    scalerUser.fit(user_train)\n",
    "    user_train = scalerUser.transform(user_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into training and test sets in 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\conda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2178: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie/item training data shape: (46549, 17)\n",
      "movie/item test  data shape: (11638, 17)\n"
     ]
    }
   ],
   "source": [
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"movie/item training data shape: {item_train.shape}\")\n",
    "print(f\"movie/item test  data shape: {item_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">     1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     0.6      </td><td style=\"text-align: center;\">   0.7   </td><td style=\"text-align: center;\">    0.6     </td><td style=\"text-align: center;\">    0.6     </td><td style=\"text-align: center;\">    0.7    </td><td style=\"text-align: center;\">   0.7   </td><td style=\"text-align: center;\">  0.5  </td><td style=\"text-align: center;\">     0.7      </td><td style=\"text-align: center;\">  0.2  </td><td style=\"text-align: center;\">   0.3    </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">   0.5    </td><td style=\"text-align: center;\">   0.5    </td><td style=\"text-align: center;\">   0.8   </td><td style=\"text-align: center;\">    0.5    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     1.6      </td><td style=\"text-align: center;\">   1.5   </td><td style=\"text-align: center;\">    1.7     </td><td style=\"text-align: center;\">    0.9     </td><td style=\"text-align: center;\">    1.0    </td><td style=\"text-align: center;\">   1.4   </td><td style=\"text-align: center;\">  0.8  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\">  1.2  </td><td style=\"text-align: center;\">   1.2    </td><td style=\"text-align: center;\">   1.6   </td><td style=\"text-align: center;\">   0.9    </td><td style=\"text-align: center;\">   1.4    </td><td style=\"text-align: center;\">   1.2   </td><td style=\"text-align: center;\">    1.0    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     0.8      </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">    0.7     </td><td style=\"text-align: center;\">    0.5     </td><td style=\"text-align: center;\">    0.6    </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">  0.3  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\">  0.7  </td><td style=\"text-align: center;\">   0.8    </td><td style=\"text-align: center;\">   0.9   </td><td style=\"text-align: center;\">   0.6    </td><td style=\"text-align: center;\">   0.2    </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">    0.6    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     -0.1     </td><td style=\"text-align: center;\">   0.2   </td><td style=\"text-align: center;\">    -0.1    </td><td style=\"text-align: center;\">    0.3     </td><td style=\"text-align: center;\">    0.7    </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">  0.2  </td><td style=\"text-align: center;\">     1.0      </td><td style=\"text-align: center;\"> -0.5  </td><td style=\"text-align: center;\">   -0.7   </td><td style=\"text-align: center;\">  -2.1   </td><td style=\"text-align: center;\">   0.5    </td><td style=\"text-align: center;\">   0.7    </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">    0.0    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    -1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     -1.3     </td><td style=\"text-align: center;\">  -0.8   </td><td style=\"text-align: center;\">    -0.8    </td><td style=\"text-align: center;\">    0.1     </td><td style=\"text-align: center;\">   -0.1    </td><td style=\"text-align: center;\">  -1.1   </td><td style=\"text-align: center;\"> -0.9  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\"> -1.5  </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -0.5   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">   -0.9   </td><td style=\"text-align: center;\">  -0.4   </td><td style=\"text-align: center;\">   -0.9    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">     1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     0.6      </td><td style=\"text-align: center;\">   0.7   </td><td style=\"text-align: center;\">    0.6     </td><td style=\"text-align: center;\">    0.6     </td><td style=\"text-align: center;\">    0.7    </td><td style=\"text-align: center;\">   0.7   </td><td style=\"text-align: center;\">  0.5  </td><td style=\"text-align: center;\">     0.7      </td><td style=\"text-align: center;\">  0.2  </td><td style=\"text-align: center;\">   0.3    </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">   0.5    </td><td style=\"text-align: center;\">   0.5    </td><td style=\"text-align: center;\">   0.8   </td><td style=\"text-align: center;\">    0.5    </td></tr>\\n<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     1.6      </td><td style=\"text-align: center;\">   1.5   </td><td style=\"text-align: center;\">    1.7     </td><td style=\"text-align: center;\">    0.9     </td><td style=\"text-align: center;\">    1.0    </td><td style=\"text-align: center;\">   1.4   </td><td style=\"text-align: center;\">  0.8  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\">  1.2  </td><td style=\"text-align: center;\">   1.2    </td><td style=\"text-align: center;\">   1.6   </td><td style=\"text-align: center;\">   0.9    </td><td style=\"text-align: center;\">   1.4    </td><td style=\"text-align: center;\">   1.2   </td><td style=\"text-align: center;\">    1.0    </td></tr>\\n<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     0.8      </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">    0.7     </td><td style=\"text-align: center;\">    0.5     </td><td style=\"text-align: center;\">    0.6    </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">  0.3  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\">  0.7  </td><td style=\"text-align: center;\">   0.8    </td><td style=\"text-align: center;\">   0.9   </td><td style=\"text-align: center;\">   0.6    </td><td style=\"text-align: center;\">   0.2    </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">    0.6    </td></tr>\\n<tr><td style=\"text-align: center;\">     1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     -0.1     </td><td style=\"text-align: center;\">   0.2   </td><td style=\"text-align: center;\">    -0.1    </td><td style=\"text-align: center;\">    0.3     </td><td style=\"text-align: center;\">    0.7    </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">  0.2  </td><td style=\"text-align: center;\">     1.0      </td><td style=\"text-align: center;\"> -0.5  </td><td style=\"text-align: center;\">   -0.7   </td><td style=\"text-align: center;\">  -2.1   </td><td style=\"text-align: center;\">   0.5    </td><td style=\"text-align: center;\">   0.7    </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">    0.0    </td></tr>\\n<tr><td style=\"text-align: center;\">    -1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     -1.3     </td><td style=\"text-align: center;\">  -0.8   </td><td style=\"text-align: center;\">    -0.8    </td><td style=\"text-align: center;\">    0.1     </td><td style=\"text-align: center;\">   -0.1    </td><td style=\"text-align: center;\">  -1.1   </td><td style=\"text-align: center;\"> -0.9  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\"> -1.5  </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -0.5   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">   -0.9   </td><td style=\"text-align: center;\">  -0.4   </td><td style=\"text-align: center;\">   -0.9    </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the scaling\n",
    "pprint_train(user_train, user_features, uvs, u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the target ratings using a Min Max Scaler to scale the target to be between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46549, 1) (11638, 1)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler((-1, 1))\n",
    "scaler.fit(y_train.reshape(-1, 1))\n",
    "ynorm_train = scaler.transform(y_train.reshape(-1, 1))\n",
    "ynorm_test = scaler.transform(y_test.reshape(-1, 1))\n",
    "print(ynorm_train.shape, ynorm_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Modelling : Neural Network for content-based filtering\n",
    "Now, let's construct a neural network as described in the figure above. It will have two networks that are combined by a dot product. We will construct the two networks. In this example, they will be identical. Note that these networks do not need to be the same. If the user content was substantially larger than the movie content, we might elect to increase the complexity of the user network relative to the movie network. In this case, the content is similar, so the networks are the same.\n",
    "\n",
    "- Use a Keras sequential model\n",
    "    - The first layer is a dense layer with 256 units and a relu activation.\n",
    "    - The second layer is a dense layer with 128 units and a relu activation.\n",
    "    - The third layer is a dense layer with `num_outputs` units and a linear or no activation.   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 32)           40864       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 32)           41376       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.l2_normalize (TFOpLambd (None, 32)           0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.l2_normalize_1 (TFOpLam (None, 32)           0           sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           tf.math.l2_normalize[0][0]       \n",
      "                                                                 tf.math.l2_normalize_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 82,240\n",
      "Trainable params: 82,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# number of output in last layer of NN\n",
    "num_outputs = 32\n",
    "\n",
    "# set the randam state\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# user network\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='linear'),\n",
    "])\n",
    "\n",
    "# movie/item network\n",
    "item_NN = tf.keras.models.Sequential([     \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='linear'),\n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a mean squared error loss and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# define cost function and optimizer\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1455/1455 [==============================] - 3s 2ms/step - loss: 0.0951\n",
      "Epoch 2/30\n",
      "1455/1455 [==============================] - 3s 2ms/step - loss: 0.0949\n",
      "Epoch 3/30\n",
      " 164/1455 [==>...........................] - ETA: 2s - loss: 0.0936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-13edf2011287>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# tf.random.set_seed(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_s\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_s\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mynorm_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tf.random.set_seed(1)\n",
    "\n",
    "model.fit([user_train[:, u_s:], item_train[:, i_s:]], ynorm_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46549, 17)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 3s 1ms/step - loss: 0.1048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10479841381311417"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], ynorm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6.1\"></a>\n",
    "### 6.1 - Predictions\n",
    "Let's use our model to make predictions in a number of circumstances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 1.0\n",
    "new_action = 1.0\n",
    "new_adventure = 1\n",
    "new_animation = 1\n",
    "new_childrens = 1\n",
    "new_comedy = 5\n",
    "new_crime = 1\n",
    "new_documentary = 1\n",
    "new_drama = 1\n",
    "new_fantasy = 1\n",
    "new_horror = 1\n",
    "new_mystery = 1\n",
    "new_romance = 5\n",
    "new_scifi = 5\n",
    "new_thriller = 1\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top-rated movies for the new user. Recall, the user vector had genres that favored Comedy and Romance.\n",
    "Below, we'll use a set of movie/item vectors, `item_vecs` that have a vector for each movie in the training/test set. This is matched with the user vector above and the scaled vectors are used to predict ratings for all the movies for our new user above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_vecs(user_vec, num_items):\n",
    "    \"\"\" given a user vector return:\n",
    "        user predict maxtrix to match the size of item_vecs \"\"\"\n",
    "    user_vecs = np.tile(user_vec, (num_items, 1))\n",
    "    return(user_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on  everything, filter on print/use\n",
    "def predict_uservec(user_vecs, item_vecs, model, u_s, i_s, scaler, ScalerUser, ScalerItem, scaledata=False):\n",
    "    \"\"\" given a user vector, does the prediction on all movies in item_vecs returns\n",
    "        an array predictions sorted by predicted rating,\n",
    "        arrays of user and item, sorted by predicted rating sorting index\n",
    "    \"\"\"\n",
    "    \n",
    "    # if data is scaled, scale new user before prediction\n",
    "    if scaledata:\n",
    "        scaled_user_vecs = ScalerUser.transform(user_vecs)\n",
    "        scaled_item_vecs = ScalerItem.transform(item_vecs)\n",
    "        y_p = model.predict([scaled_user_vecs[:, u_s:], scaled_item_vecs[:, i_s:]])\n",
    "    else:\n",
    "        y_p = model.predict([user_vecs[:, u_s:], item_vecs[:, i_s:]])\n",
    "        \n",
    "    y_pu = scaler.inverse_transform(y_p)\n",
    "    \n",
    "    # check if prediction is positive\n",
    "    if np.any(y_pu < 0) : \n",
    "        print(\"Error, expected all positive predictions\")\n",
    "        \n",
    "    # get largest rating first\n",
    "    sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  \n",
    "    sorted_ypu   = y_pu[sorted_index]\n",
    "    sorted_items = item_vecs[sorted_index]\n",
    "    sorted_user  = user_vecs[sorted_index]\n",
    "    return(sorted_index, sorted_ypu, sorted_items, sorted_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">    y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                                      </th><th>genres                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">4.367  </td><td style=\"text-align: right;\">     31221</td><td style=\"text-align: right;\">     2.05   </td><td>Elektra (2005)                                                             </td><td>Action|Adventure|Crime|Drama  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36698</td><td style=\"text-align: right;\">     46335</td><td style=\"text-align: right;\">     2.09091</td><td>Fast and the Furious: Tokyo Drift, The (Fast and the Furious 3, The) (2006)</td><td>Action|Crime|Drama|Thriller   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36695</td><td style=\"text-align: right;\">      4254</td><td style=\"text-align: right;\">     2.19231</td><td>Crocodile Dundee in Los Angeles (2001)                                     </td><td>Comedy|Drama                  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36693</td><td style=\"text-align: right;\">     43928</td><td style=\"text-align: right;\">     1.92308</td><td>Ultraviolet (2006)                                                         </td><td>Action|Fantasy|Sci-Fi|Thriller</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36691</td><td style=\"text-align: right;\">     76175</td><td style=\"text-align: right;\">     2.30769</td><td>Clash of the Titans (2010)                                                 </td><td>Action|Adventure|Drama|Fantasy</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.3669 </td><td style=\"text-align: right;\">      4228</td><td style=\"text-align: right;\">     2.15   </td><td>Heartbreakers (2001)                                                       </td><td>Comedy|Crime|Romance          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36688</td><td style=\"text-align: right;\">      6482</td><td style=\"text-align: right;\">     1.95455</td><td>Dumb and Dumberer: When Harry Met Lloyd (2003)                             </td><td>Comedy                        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36688</td><td style=\"text-align: right;\">      8907</td><td style=\"text-align: right;\">     2.34615</td><td>Shark Tale (2004)                                                          </td><td>Animation|Children|Comedy     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36688</td><td style=\"text-align: right;\">     63992</td><td style=\"text-align: right;\">     2.40909</td><td>Twilight (2008)                                                            </td><td>Drama|Fantasy|Romance|Thriller</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4.36686</td><td style=\"text-align: right;\">     33836</td><td style=\"text-align: right;\">     2.26923</td><td>Bewitched (2005)                                                           </td><td>Comedy|Fantasy|Romance        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">    y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                                      </th><th>genres                        </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">4.367  </td><td style=\"text-align: right;\">     31221</td><td style=\"text-align: right;\">     2.05   </td><td>Elektra (2005)                                                             </td><td>Action|Adventure|Crime|Drama  </td></tr>\\n<tr><td style=\"text-align: right;\">4.36698</td><td style=\"text-align: right;\">     46335</td><td style=\"text-align: right;\">     2.09091</td><td>Fast and the Furious: Tokyo Drift, The (Fast and the Furious 3, The) (2006)</td><td>Action|Crime|Drama|Thriller   </td></tr>\\n<tr><td style=\"text-align: right;\">4.36695</td><td style=\"text-align: right;\">      4254</td><td style=\"text-align: right;\">     2.19231</td><td>Crocodile Dundee in Los Angeles (2001)                                     </td><td>Comedy|Drama                  </td></tr>\\n<tr><td style=\"text-align: right;\">4.36693</td><td style=\"text-align: right;\">     43928</td><td style=\"text-align: right;\">     1.92308</td><td>Ultraviolet (2006)                                                         </td><td>Action|Fantasy|Sci-Fi|Thriller</td></tr>\\n<tr><td style=\"text-align: right;\">4.36691</td><td style=\"text-align: right;\">     76175</td><td style=\"text-align: right;\">     2.30769</td><td>Clash of the Titans (2010)                                                 </td><td>Action|Adventure|Drama|Fantasy</td></tr>\\n<tr><td style=\"text-align: right;\">4.3669 </td><td style=\"text-align: right;\">      4228</td><td style=\"text-align: right;\">     2.15   </td><td>Heartbreakers (2001)                                                       </td><td>Comedy|Crime|Romance          </td></tr>\\n<tr><td style=\"text-align: right;\">4.36688</td><td style=\"text-align: right;\">      6482</td><td style=\"text-align: right;\">     1.95455</td><td>Dumb and Dumberer: When Harry Met Lloyd (2003)                             </td><td>Comedy                        </td></tr>\\n<tr><td style=\"text-align: right;\">4.36688</td><td style=\"text-align: right;\">      8907</td><td style=\"text-align: right;\">     2.34615</td><td>Shark Tale (2004)                                                          </td><td>Animation|Children|Comedy     </td></tr>\\n<tr><td style=\"text-align: right;\">4.36688</td><td style=\"text-align: right;\">     63992</td><td style=\"text-align: right;\">     2.40909</td><td>Twilight (2008)                                                            </td><td>Drama|Fantasy|Romance|Thriller</td></tr>\\n<tr><td style=\"text-align: right;\">4.36686</td><td style=\"text-align: right;\">     33836</td><td style=\"text-align: right;\">     2.26923</td><td>Bewitched (2005)                                                           </td><td>Comedy|Fantasy|Romance        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate and replicate the user vector to match the number movies in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "\n",
    "# scale the vectors and make predictions for all movies. Return results sorted by rating.\n",
    "sorted_index, sorted_ypu, sorted_items, sorted_user = predict_uservec(user_vecs,  item_vecs, model, u_s, i_s, \n",
    "                                                                       scaler, scalerUser, scalerItem, scaledata=scaledata)\n",
    "\n",
    "print_pred_movies(sorted_ypu, sorted_user, sorted_items, movie_dict, maxcount = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6.2\"></a>\n",
    "### 6.2 -  Finding Similar Items\n",
    "The neural network above produces two feature vectors, a user feature vector $v_u$, and a movie feature vector, $v_m$. These are 32 entry vectors whose values are difficult to interpret. However, similar items will have similar vectors. This information can be used to make recommendations. For example, if a user has rated \"Toy Story 3\" highly, one could recommend similar movies by selecting movies with similar movie feature vectors.\n",
    "\n",
    "A similarity measure is the squared distance between the two vectors $ \\mathbf{v_m^{(k)}}$ and $\\mathbf{v_m^{(i)}}$ :\n",
    "$$\\left\\Vert \\mathbf{v_m^{(k)}} - \\mathbf{v_m^{(i)}}  \\right\\Vert^2 = \\sum_{l=1}^{n}(v_{m_l}^{(k)} - v_{m_l}^{(i)})^2\\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix of distances between movies can be computed once when the model is trained and then reused for new recommendations without retraining. The first step, once a model is trained, is to obtain the movie feature vector, $v_m$, for each of the movies. To do this, we will use the trained `item_NN` and build a small model to allow us to run the movie vectors through it to generate $v_m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32)                41376     \n",
      "_________________________________________________________________\n",
      "tf.math.l2_normalize_2 (TFOp (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 41,376\n",
      "Trainable params: 41,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_item_m = tf.keras.layers.Input(shape=(num_item_features))    # input layer\n",
    "vm_m = item_NN(input_item_m)                                       # use the trained item_NN\n",
    "vm_m = tf.linalg.l2_normalize(vm_m, axis=1)                        # incorporate normalization as was done in the original model\n",
    "model_m = Model(input_item_m, vm_m)                                \n",
    "model_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of all predicted movie feature vectors: (1883, 32)\n"
     ]
    }
   ],
   "source": [
    "scaled_item_vecs = scalerItem.transform(item_vecs)                     # scale item vector\n",
    "vms = model_m.predict(scaled_item_vecs[:,i_s:])                        # predict using the trained item_nn to get movie vector \n",
    "print(f\"size of all predicted movie feature vectors: {vms.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then find the closest movie by finding the minimum along each row. We will make use of [numpy masked arrays](https://numpy.org/doc/1.21/user/tutorial-ma.html) to avoid selecting the same movie. The masked values along the diagonal won't be included in the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq_dist(a,b):\n",
    "    \"\"\"\n",
    "    Returns the squared distance between two vectors\n",
    "    \"\"\"        \n",
    "    d = sum(np.square(a-b))\n",
    "  \n",
    "    return (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>movie1                                </th><th>genres   </th><th>movie2                                                 </th><th>genres   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Save the Last Dance (2001)            </td><td>Drama    </td><td>Flightplan (2005)                                      </td><td>Drama    </td></tr>\n",
       "<tr><td>Save the Last Dance (2001)            </td><td>Romance  </td><td>He&#x27;s Just Not That Into You (2009)                     </td><td>Romance  </td></tr>\n",
       "<tr><td>Wedding Planner, The (2001)           </td><td>Comedy   </td><td>Mr. Deeds (2002)                                       </td><td>Comedy   </td></tr>\n",
       "<tr><td>Wedding Planner, The (2001)           </td><td>Romance  </td><td>Mr. Deeds (2002)                                       </td><td>Romance  </td></tr>\n",
       "<tr><td>Hannibal (2001)                       </td><td>Horror   </td><td>Resident Evil: Extinction (2007)                       </td><td>Horror   </td></tr>\n",
       "<tr><td>Hannibal (2001)                       </td><td>Thriller </td><td>Resident Evil: Extinction (2007)                       </td><td>Thriller </td></tr>\n",
       "<tr><td>Saving Silverman (Evil Woman) (2001)  </td><td>Comedy   </td><td>Benchwarmers, The (2006)                               </td><td>Comedy   </td></tr>\n",
       "<tr><td>Saving Silverman (Evil Woman) (2001)  </td><td>Romance  </td><td>Mona Lisa Smile (2003)                                 </td><td>Romance  </td></tr>\n",
       "<tr><td>Down to Earth (2001)                  </td><td>Comedy   </td><td>Legally Blonde 2: Red, White &amp; Blonde (2003)           </td><td>Comedy   </td></tr>\n",
       "<tr><td>Down to Earth (2001)                  </td><td>Fantasy  </td><td>Twilight (2008)                                        </td><td>Fantasy  </td></tr>\n",
       "<tr><td>Down to Earth (2001)                  </td><td>Romance  </td><td>Sex and the City (2008)                                </td><td>Romance  </td></tr>\n",
       "<tr><td>Mexican, The (2001)                   </td><td>Action   </td><td>Island, The (2005)                                     </td><td>Action   </td></tr>\n",
       "<tr><td>Mexican, The (2001)                   </td><td>Comedy   </td><td>Anchorman 2: The Legend Continues (2013)               </td><td>Comedy   </td></tr>\n",
       "<tr><td>15 Minutes (2001)                     </td><td>Thriller </td><td>Panic Room (2002)                                      </td><td>Thriller </td></tr>\n",
       "<tr><td>Heartbreakers (2001)                  </td><td>Comedy   </td><td>Animal, The (2001)                                     </td><td>Comedy   </td></tr>\n",
       "<tr><td>Heartbreakers (2001)                  </td><td>Crime    </td><td>Fun with Dick and Jane (2005)                          </td><td>Crime    </td></tr>\n",
       "<tr><td>Heartbreakers (2001)                  </td><td>Romance  </td><td>Fun with Dick and Jane (2005)                          </td><td>Crime    </td></tr>\n",
       "<tr><td>Spy Kids (2001)                       </td><td>Action   </td><td>Resident Evil: Extinction (2007)                       </td><td>Action   </td></tr>\n",
       "<tr><td>Spy Kids (2001)                       </td><td>Adventure</td><td>Die Another Day (2002)                                 </td><td>Adventure</td></tr>\n",
       "<tr><td>Spy Kids (2001)                       </td><td>Children </td><td>Shrek the Third (2007)                                 </td><td>Animation</td></tr>\n",
       "<tr><td>Spy Kids (2001)                       </td><td>Comedy   </td><td>Julie &amp; Julia (2009)                                   </td><td>Comedy   </td></tr>\n",
       "<tr><td>Along Came a Spider (2001)            </td><td>Action   </td><td>Wanted (2008)                                          </td><td>Action   </td></tr>\n",
       "<tr><td>Along Came a Spider (2001)            </td><td>Crime    </td><td>Death Proof (2007)                                     </td><td>Crime    </td></tr>\n",
       "<tr><td>Along Came a Spider (2001)            </td><td>Mystery  </td><td>Saw (2004)                                             </td><td>Mystery  </td></tr>\n",
       "<tr><td>Along Came a Spider (2001)            </td><td>Thriller </td><td>Wanted (2008)                                          </td><td>Thriller </td></tr>\n",
       "<tr><td>Blow (2001)                           </td><td>Crime    </td><td>Layer Cake (2004)                                      </td><td>Crime    </td></tr>\n",
       "<tr><td>Blow (2001)                           </td><td>Drama    </td><td>Help, The (2011)                                       </td><td>Drama    </td></tr>\n",
       "<tr><td>Bridget Jones&#x27;s Diary (2001)          </td><td>Comedy   </td><td>Wallace &amp; Gromit in The Curse of the Were-Rabbit (2005)</td><td>Comedy   </td></tr>\n",
       "<tr><td>Bridget Jones&#x27;s Diary (2001)          </td><td>Drama    </td><td>Dirty Pretty Things (2002)                             </td><td>Drama    </td></tr>\n",
       "<tr><td>Bridget Jones&#x27;s Diary (2001)          </td><td>Romance  </td><td>Punch-Drunk Love (2002)                                </td><td>Romance  </td></tr>\n",
       "<tr><td>Joe Dirt (2001)                       </td><td>Adventure</td><td>Charlie&#x27;s Angels: Full Throttle (2003)                 </td><td>Adventure</td></tr>\n",
       "<tr><td>Joe Dirt (2001)                       </td><td>Comedy   </td><td>Charlie&#x27;s Angels: Full Throttle (2003)                 </td><td>Comedy   </td></tr>\n",
       "<tr><td>Joe Dirt (2001)                       </td><td>Mystery  </td><td>Haunted Mansion, The (2003)                            </td><td>Children </td></tr>\n",
       "<tr><td>Joe Dirt (2001)                       </td><td>Romance  </td><td>Sex and the City (2008)                                </td><td>Romance  </td></tr>\n",
       "<tr><td>Crocodile Dundee in Los Angeles (2001)</td><td>Comedy   </td><td>Fun with Dick and Jane (2005)                          </td><td>Comedy   </td></tr>\n",
       "<tr><td>Crocodile Dundee in Los Angeles (2001)</td><td>Drama    </td><td>Bewitched (2005)                                       </td><td>Romance  </td></tr>\n",
       "<tr><td>Mummy Returns, The (2001)             </td><td>Action   </td><td>Underworld: Evolution (2006)                           </td><td>Action   </td></tr>\n",
       "<tr><td>Mummy Returns, The (2001)             </td><td>Adventure</td><td>Star Wars: The Last Jedi (2017)                        </td><td>Adventure</td></tr>\n",
       "<tr><td>Mummy Returns, The (2001)             </td><td>Comedy   </td><td>American Wedding (American Pie 3) (2003)               </td><td>Comedy   </td></tr>\n",
       "<tr><td>Mummy Returns, The (2001)             </td><td>Thriller </td><td>Smokin&#x27; Aces (2006)                                    </td><td>Thriller </td></tr>\n",
       "<tr><td>Knight&#x27;s Tale, A (2001)               </td><td>Action   </td><td>Cloverfield (2008)                                     </td><td>Action   </td></tr>\n",
       "<tr><td>Knight&#x27;s Tale, A (2001)               </td><td>Comedy   </td><td>Anchorman 2: The Legend Continues (2013)               </td><td>Comedy   </td></tr>\n",
       "<tr><td>Knight&#x27;s Tale, A (2001)               </td><td>Romance  </td><td>Nick and Norah&#x27;s Infinite Playlist (2008)              </td><td>Romance  </td></tr>\n",
       "<tr><td>Shrek (2001)                          </td><td>Adventure</td><td>Monsters, Inc. (2001)                                  </td><td>Adventure</td></tr>\n",
       "<tr><td>Shrek (2001)                          </td><td>Animation</td><td>Monsters, Inc. (2001)                                  </td><td>Animation</td></tr>\n",
       "<tr><td>Shrek (2001)                          </td><td>Children </td><td>Monsters, Inc. (2001)                                  </td><td>Children </td></tr>\n",
       "<tr><td>Shrek (2001)                          </td><td>Comedy   </td><td>Monsters, Inc. (2001)                                  </td><td>Comedy   </td></tr>\n",
       "<tr><td>Shrek (2001)                          </td><td>Fantasy  </td><td>Monsters, Inc. (2001)                                  </td><td>Fantasy  </td></tr>\n",
       "<tr><td>Shrek (2001)                          </td><td>Romance  </td><td>Far from Heaven (2002)                                 </td><td>Romance  </td></tr>\n",
       "<tr><td>Animal, The (2001)                    </td><td>Comedy   </td><td>Heartbreakers (2001)                                   </td><td>Comedy   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>movie1                                </th><th>genres   </th><th>movie2                                                 </th><th>genres   </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>Save the Last Dance (2001)            </td><td>Drama    </td><td>Flightplan (2005)                                      </td><td>Drama    </td></tr>\\n<tr><td>Save the Last Dance (2001)            </td><td>Romance  </td><td>He&#x27;s Just Not That Into You (2009)                     </td><td>Romance  </td></tr>\\n<tr><td>Wedding Planner, The (2001)           </td><td>Comedy   </td><td>Mr. Deeds (2002)                                       </td><td>Comedy   </td></tr>\\n<tr><td>Wedding Planner, The (2001)           </td><td>Romance  </td><td>Mr. Deeds (2002)                                       </td><td>Romance  </td></tr>\\n<tr><td>Hannibal (2001)                       </td><td>Horror   </td><td>Resident Evil: Extinction (2007)                       </td><td>Horror   </td></tr>\\n<tr><td>Hannibal (2001)                       </td><td>Thriller </td><td>Resident Evil: Extinction (2007)                       </td><td>Thriller </td></tr>\\n<tr><td>Saving Silverman (Evil Woman) (2001)  </td><td>Comedy   </td><td>Benchwarmers, The (2006)                               </td><td>Comedy   </td></tr>\\n<tr><td>Saving Silverman (Evil Woman) (2001)  </td><td>Romance  </td><td>Mona Lisa Smile (2003)                                 </td><td>Romance  </td></tr>\\n<tr><td>Down to Earth (2001)                  </td><td>Comedy   </td><td>Legally Blonde 2: Red, White &amp; Blonde (2003)           </td><td>Comedy   </td></tr>\\n<tr><td>Down to Earth (2001)                  </td><td>Fantasy  </td><td>Twilight (2008)                                        </td><td>Fantasy  </td></tr>\\n<tr><td>Down to Earth (2001)                  </td><td>Romance  </td><td>Sex and the City (2008)                                </td><td>Romance  </td></tr>\\n<tr><td>Mexican, The (2001)                   </td><td>Action   </td><td>Island, The (2005)                                     </td><td>Action   </td></tr>\\n<tr><td>Mexican, The (2001)                   </td><td>Comedy   </td><td>Anchorman 2: The Legend Continues (2013)               </td><td>Comedy   </td></tr>\\n<tr><td>15 Minutes (2001)                     </td><td>Thriller </td><td>Panic Room (2002)                                      </td><td>Thriller </td></tr>\\n<tr><td>Heartbreakers (2001)                  </td><td>Comedy   </td><td>Animal, The (2001)                                     </td><td>Comedy   </td></tr>\\n<tr><td>Heartbreakers (2001)                  </td><td>Crime    </td><td>Fun with Dick and Jane (2005)                          </td><td>Crime    </td></tr>\\n<tr><td>Heartbreakers (2001)                  </td><td>Romance  </td><td>Fun with Dick and Jane (2005)                          </td><td>Crime    </td></tr>\\n<tr><td>Spy Kids (2001)                       </td><td>Action   </td><td>Resident Evil: Extinction (2007)                       </td><td>Action   </td></tr>\\n<tr><td>Spy Kids (2001)                       </td><td>Adventure</td><td>Die Another Day (2002)                                 </td><td>Adventure</td></tr>\\n<tr><td>Spy Kids (2001)                       </td><td>Children </td><td>Shrek the Third (2007)                                 </td><td>Animation</td></tr>\\n<tr><td>Spy Kids (2001)                       </td><td>Comedy   </td><td>Julie &amp; Julia (2009)                                   </td><td>Comedy   </td></tr>\\n<tr><td>Along Came a Spider (2001)            </td><td>Action   </td><td>Wanted (2008)                                          </td><td>Action   </td></tr>\\n<tr><td>Along Came a Spider (2001)            </td><td>Crime    </td><td>Death Proof (2007)                                     </td><td>Crime    </td></tr>\\n<tr><td>Along Came a Spider (2001)            </td><td>Mystery  </td><td>Saw (2004)                                             </td><td>Mystery  </td></tr>\\n<tr><td>Along Came a Spider (2001)            </td><td>Thriller </td><td>Wanted (2008)                                          </td><td>Thriller </td></tr>\\n<tr><td>Blow (2001)                           </td><td>Crime    </td><td>Layer Cake (2004)                                      </td><td>Crime    </td></tr>\\n<tr><td>Blow (2001)                           </td><td>Drama    </td><td>Help, The (2011)                                       </td><td>Drama    </td></tr>\\n<tr><td>Bridget Jones&#x27;s Diary (2001)          </td><td>Comedy   </td><td>Wallace &amp; Gromit in The Curse of the Were-Rabbit (2005)</td><td>Comedy   </td></tr>\\n<tr><td>Bridget Jones&#x27;s Diary (2001)          </td><td>Drama    </td><td>Dirty Pretty Things (2002)                             </td><td>Drama    </td></tr>\\n<tr><td>Bridget Jones&#x27;s Diary (2001)          </td><td>Romance  </td><td>Punch-Drunk Love (2002)                                </td><td>Romance  </td></tr>\\n<tr><td>Joe Dirt (2001)                       </td><td>Adventure</td><td>Charlie&#x27;s Angels: Full Throttle (2003)                 </td><td>Adventure</td></tr>\\n<tr><td>Joe Dirt (2001)                       </td><td>Comedy   </td><td>Charlie&#x27;s Angels: Full Throttle (2003)                 </td><td>Comedy   </td></tr>\\n<tr><td>Joe Dirt (2001)                       </td><td>Mystery  </td><td>Haunted Mansion, The (2003)                            </td><td>Children </td></tr>\\n<tr><td>Joe Dirt (2001)                       </td><td>Romance  </td><td>Sex and the City (2008)                                </td><td>Romance  </td></tr>\\n<tr><td>Crocodile Dundee in Los Angeles (2001)</td><td>Comedy   </td><td>Fun with Dick and Jane (2005)                          </td><td>Comedy   </td></tr>\\n<tr><td>Crocodile Dundee in Los Angeles (2001)</td><td>Drama    </td><td>Bewitched (2005)                                       </td><td>Romance  </td></tr>\\n<tr><td>Mummy Returns, The (2001)             </td><td>Action   </td><td>Underworld: Evolution (2006)                           </td><td>Action   </td></tr>\\n<tr><td>Mummy Returns, The (2001)             </td><td>Adventure</td><td>Star Wars: The Last Jedi (2017)                        </td><td>Adventure</td></tr>\\n<tr><td>Mummy Returns, The (2001)             </td><td>Comedy   </td><td>American Wedding (American Pie 3) (2003)               </td><td>Comedy   </td></tr>\\n<tr><td>Mummy Returns, The (2001)             </td><td>Thriller </td><td>Smokin&#x27; Aces (2006)                                    </td><td>Thriller </td></tr>\\n<tr><td>Knight&#x27;s Tale, A (2001)               </td><td>Action   </td><td>Cloverfield (2008)                                     </td><td>Action   </td></tr>\\n<tr><td>Knight&#x27;s Tale, A (2001)               </td><td>Comedy   </td><td>Anchorman 2: The Legend Continues (2013)               </td><td>Comedy   </td></tr>\\n<tr><td>Knight&#x27;s Tale, A (2001)               </td><td>Romance  </td><td>Nick and Norah&#x27;s Infinite Playlist (2008)              </td><td>Romance  </td></tr>\\n<tr><td>Shrek (2001)                          </td><td>Adventure</td><td>Monsters, Inc. (2001)                                  </td><td>Adventure</td></tr>\\n<tr><td>Shrek (2001)                          </td><td>Animation</td><td>Monsters, Inc. (2001)                                  </td><td>Animation</td></tr>\\n<tr><td>Shrek (2001)                          </td><td>Children </td><td>Monsters, Inc. (2001)                                  </td><td>Children </td></tr>\\n<tr><td>Shrek (2001)                          </td><td>Comedy   </td><td>Monsters, Inc. (2001)                                  </td><td>Comedy   </td></tr>\\n<tr><td>Shrek (2001)                          </td><td>Fantasy  </td><td>Monsters, Inc. (2001)                                  </td><td>Fantasy  </td></tr>\\n<tr><td>Shrek (2001)                          </td><td>Romance  </td><td>Far from Heaven (2002)                                 </td><td>Romance  </td></tr>\\n<tr><td>Animal, The (2001)                    </td><td>Comedy   </td><td>Heartbreakers (2001)                                   </td><td>Comedy   </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 50\n",
    "dim = len(vms)\n",
    "dist = np.zeros((dim,dim))    # build a matrix\n",
    "\n",
    "# find distance for all movie\n",
    "for i in range(dim):\n",
    "    for j in range(dim):\n",
    "        dist[i,j] = sq_dist(vms[i, :], vms[j, :])\n",
    "        \n",
    "        \n",
    "m_dist = ma.masked_array(dist, mask=np.identity(dist.shape[0]))  # mask the diagonal\n",
    "\n",
    "disp = [[\"movie1\", \"genres\", \"movie2\", \"genres\"]]\n",
    "for i in range(count):\n",
    "    min_idx = np.argmin(m_dist[i])\n",
    "    movie1_id = int(item_vecs[i,0])\n",
    "    movie2_id = int(item_vecs[min_idx,0])\n",
    "    genre1,_  = get_item_genre(item_vecs[i,:], ivs, item_features)\n",
    "    genre2,_  = get_item_genre(item_vecs[min_idx,:], ivs, item_features)\n",
    "\n",
    "    disp.append( [movie_dict[movie1_id]['title'], genre1,\n",
    "                  movie_dict[movie2_id]['title'], genre2]\n",
    "               )\n",
    "table = tabulate.tabulate(disp, tablefmt='html', headers=\"firstrow\", floatfmt=[\".1f\", \".1f\", \".0f\", \".2f\", \".2f\"])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"7\"></a>\n",
    "## 7 - Conclusion: <img align=\"left\" src=\"./images/film_award.png\" style=\" width:40px;\">\n",
    "We have completed a content-based recommender system.    \n",
    "\n",
    "**Future Scope-**\n",
    "\n",
    "The user content can be greatly expanded to incorporate more information about the user if it is available.  Items are not limited to movies. This can be used to recommend any item, books, cars or items that are similar to an item in your 'shopping cart'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
